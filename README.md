# Intelligent Navigation of Text-Based Games


## Generating Games

To generate a single game, run a command matching the following format:

`tw-make tw-coin_collector --level {level} --output tw_games/{folder_name}/`

To generate a set of games, run a command matching the following format:

`for i in $(seq 1 {num_games}); do tw-make tw-coin_collector --level {level} --output tw_games/{folder_name}/; done`

where `level` is defined as follows:

|   `level`  |  mode  |  quest length |     total rooms     |  distractor rooms  |
|:----------:|:------:|:-------------:|:-------------------:|:------------------:|
|  1 to 100  |  easy  |    `level`    |       `level`       |        none        |
| 101 to 200 | medium | `level` % 100 | 2 * (`level` % 100) | one per chain room |
| 201 to 300 |  hard  | `level` % 100 | 3 * (`level` % 100) | two per chain room |


## Agents

`RandomAgent` selects actions randomly, ignoring text generated by the game.

`DQN Agent` uses a follows the DQN model, aiming to learn over time how to best play the games. This agent uses a prioritised replay memory to store historical information, a deep neural network to score actions, and an epsilon-greedy policy to balance exploration and exploitation.


## Training and Testing

To test a random agent on a set of games, run a command of the following format:

`python3 main.py random [world_folder]`

To train and test DQNAgent, run a command of the following format:

`python3 main.py dqn [single|multiple|zero-shot] [world_folder] {test_world_folders}`

The argument `[single|multiple|zero-shot]` determines which experiment is run. If `zero-shot` is selected, a `test_world_folder` must additionally be provided.

The three types of experiment which can be run on the DQN agent are described below.
- `single`: Investigate whether the DQN agent can learn to solve single games. For each game in `world_folder`, train the agent on the game for 2000 epochs.
- `multiple`: Investigate whether the DQN agent can learn to solve a set of games. Train the agent on all games in `world_folder` for 2000 epochs.
- `zero-shot`: Investigate whether a trained DQN agent can generalise to unseen games. Train the agent on all games in `world_folder` for 3000 epochs. Throughout training, test the agent on each set of games in `test_world_folders`.